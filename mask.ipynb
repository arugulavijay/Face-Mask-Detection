{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_BRZSlb5eNM"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mr6fkj51-_W4"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIgvAfX5_KN3"
      },
      "outputs": [],
      "source": [
        "# create a kaggle folder\n",
        "!mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uq5TgXmt_PdK"
      },
      "outputs": [],
      "source": [
        "#copy the kaggle.json to folder created\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7RCiX5Z_uUP"
      },
      "outputs": [],
      "source": [
        "# permission for the json to act\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-37VhBPP_4cB"
      },
      "outputs": [],
      "source": [
        "#to list all datasets\n",
        "!kaggle datasets lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeCsU_NrAWMj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Step 1: Define valid credentials\n",
        "kaggle_api_token = {\n",
        "    \"username\": \"arugulavijayprasad\",\n",
        "    \"key\": \"d6c63899d282cc48329562c08ae85895\"\n",
        "}\n",
        "\n",
        "# Step 2: Save to kaggle.json\n",
        "with open(\"kaggle.json\", \"w\") as file:\n",
        "    json.dump(kaggle_api_token, file)\n",
        "\n",
        "# Step 3: Create ~/.kaggle if not exists\n",
        "kaggle_dir = os.path.expanduser(\"~/.kaggle\")\n",
        "os.makedirs(kaggle_dir, exist_ok=True)\n",
        "\n",
        "# Step 4: Move kaggle.json to ~/.kaggle\n",
        "shutil.move(\"kaggle.json\", os.path.join(kaggle_dir, \"kaggle.json\"))\n",
        "\n",
        "# Step 5: Set correct permissions\n",
        "os.chmod(os.path.join(kaggle_dir, \"kaggle.json\"), 0o600)\n",
        "\n",
        "print(\"âœ… kaggle.json is properly placed and configured.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvngY1ydAaNu"
      },
      "outputs": [],
      "source": [
        "#to list all datasets\n",
        "!kaggle datasets list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMBiyCCHAp03"
      },
      "outputs": [],
      "source": [
        "# API to fetch the dataset from Kaggle\n",
        "!kaggle datasets download -d omkargurav/face-mask-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yAB4qIABPYb"
      },
      "source": [
        "**Importing Face Mask Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qe_TRElSBbsh"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/face-mask-dataset.zip'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ZipFile\n\u001b[0;32m      3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/face-mask-dataset.zip\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ZipFile(dataset,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;28mzip\u001b[39m:\n\u001b[0;32m      6\u001b[0m   \u001b[38;5;28mzip\u001b[39m\u001b[38;5;241m.\u001b[39mextractall()\n\u001b[0;32m      7\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe dataset is extracted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\zipfile\\__init__.py:1331\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1331\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mopen(file, filemode)\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m   1333\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/face-mask-dataset.zip'"
          ]
        }
      ],
      "source": [
        "# extracting the compessed Dataset\n",
        "from zipfile import ZipFile\n",
        "dataset = '/content/face-mask-dataset.zip'\n",
        "\n",
        "with ZipFile(dataset,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The dataset is extracted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uszk5qiAByDb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'ls' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdkbQUi5CyI8"
      },
      "source": [
        "Importing the Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iFBhlr-C4Qb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xt5kN-udDW-w"
      },
      "outputs": [],
      "source": [
        "with_mask_files = os.listdir('/content/data/with_mask')\n",
        "print(with_mask_files[0:5])\n",
        "print(with_mask_files[-5:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DblTkx0JD16b"
      },
      "outputs": [],
      "source": [
        "without_mask_files = os.listdir('/content/data/without_mask')\n",
        "print(without_mask_files[0:5])\n",
        "print(without_mask_files[-5:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jbb3LwcOELpu"
      },
      "outputs": [],
      "source": [
        "print('Number of with mask images:', len(with_mask_files))\n",
        "print('Number of without mask images:', len(without_mask_files))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXrQlPH1EXNT"
      },
      "source": [
        "**Creating Labels for the two class of Images**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnjz6JEPEZDz"
      },
      "source": [
        "with mask  -->  1\n",
        "\n",
        "without mask --> 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQS8KtKKEc31"
      },
      "outputs": [],
      "source": [
        "# create the labels\n",
        "\n",
        "with_mask_labels = [1]*3725\n",
        "\n",
        "without_mask_labels = [0]*3828"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d69JPMF2Q8WP"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3bDJEx0E8bg"
      },
      "outputs": [],
      "source": [
        "print(with_mask_labels[0:5])\n",
        "\n",
        "print(without_mask_labels[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gm28MQFqGWaI"
      },
      "outputs": [],
      "source": [
        "print(len(with_mask_labels))\n",
        "print(len(without_mask_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxiL05j8Ga3y"
      },
      "outputs": [],
      "source": [
        "labels = with_mask_labels + without_mask_labels\n",
        "\n",
        "print(len(labels))\n",
        "print(labels[0:5])\n",
        "print(labels[-5:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59WkpipOGe3m"
      },
      "source": [
        "**Displaying the Images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nU3GDIy_Gm-h"
      },
      "outputs": [],
      "source": [
        "# displaying with mask image\n",
        "img = mpimg.imread('/content/data/with_mask/with_mask_1545.jpg')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haimfJ7CGw7j"
      },
      "outputs": [],
      "source": [
        "# displaying without mask image\n",
        "img = mpimg.imread('/content/data/without_mask/without_mask_2925.jpg')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvqsdtZdG3ND"
      },
      "source": [
        "**Image Processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyAQPX-GG4fH"
      },
      "source": [
        "1.Resize the Images\n",
        "\n",
        "2.Convert the images to numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAQkwfPIGyf2"
      },
      "outputs": [],
      "source": [
        "# convert images to numpy arrays+\n",
        "\n",
        "with_mask_path = '/content/data/with_mask/'\n",
        "\n",
        "data = []\n",
        "\n",
        "for img_file in with_mask_files:\n",
        "\n",
        "  image = Image.open(with_mask_path + img_file)\n",
        "  image = image.resize((128,128))\n",
        "  image = image.convert('RGB')\n",
        "  image = np.array(image)\n",
        "  data.append(image)\n",
        "\n",
        "\n",
        "\n",
        "without_mask_path = '/content/data/without_mask/'\n",
        "\n",
        "\n",
        "for img_file in without_mask_files:\n",
        "\n",
        "  image = Image.open(without_mask_path + img_file)\n",
        "  image = image.resize((128,128))\n",
        "  image = image.convert('RGB')\n",
        "  image = np.array(image)\n",
        "  data.append(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPc63GuVG2wr"
      },
      "outputs": [],
      "source": [
        "type(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ix59G0lxHjWh"
      },
      "outputs": [],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUHyLUYFHjZb"
      },
      "outputs": [],
      "source": [
        "data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBTHkrmkHjcN"
      },
      "outputs": [],
      "source": [
        "type(data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRN5iZ0yHjen"
      },
      "outputs": [],
      "source": [
        "data[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--PScqGsHjkA"
      },
      "outputs": [],
      "source": [
        "# converting image list and label list to numpy arrays\n",
        "\n",
        "X = np.array(data)\n",
        "Y = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDyLWkVKHjnd"
      },
      "outputs": [],
      "source": [
        "type(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1avXnfPI-uv"
      },
      "outputs": [],
      "source": [
        "type(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BTwZj_gI-xy"
      },
      "outputs": [],
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFruA6M1I-0t"
      },
      "outputs": [],
      "source": [
        "print(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpdhSt8-JQDJ"
      },
      "source": [
        "**Train Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFdg5kvJI-3R"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9i3375PYI-55"
      },
      "outputs": [],
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sD6Hl3bKI-8g"
      },
      "outputs": [],
      "source": [
        "# scaling the data\n",
        "\n",
        "X_train_scaled = X_train/255\n",
        "\n",
        "X_test_scaled = X_test/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hESeFBM-I-_O"
      },
      "outputs": [],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeECcPWaI_BZ"
      },
      "outputs": [],
      "source": [
        "X_train_scaled[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myHNzeFFKHNi"
      },
      "source": [
        "**Building a Convolutional Neural Networks (CNN)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzLjX0udI_D6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqxAmcEcI_HJ"
      },
      "outputs": [],
      "source": [
        "num_of_classes = 2\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(128,128,3)))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "model.add(keras.layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(keras.layers.Dense(num_of_classes, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwRPqcgJI_Km"
      },
      "outputs": [],
      "source": [
        "# compile the neural network\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3kEFHOdKawT"
      },
      "outputs": [],
      "source": [
        "# training the neural network\n",
        "history = model.fit(X_train_scaled, Y_train, validation_split=0.1, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUUz6WR7KjWp"
      },
      "source": [
        "**Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsOlgoa4Ko2C"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(X_test_scaled, Y_test)\n",
        "print('Test Accuracy =', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8IebKu0Kzgn"
      },
      "outputs": [],
      "source": [
        "h = history\n",
        "\n",
        "# plot the loss value\n",
        "plt.plot(h.history['loss'], label='train loss')\n",
        "plt.plot(h.history['val_loss'], label='validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# plot the accuracy value\n",
        "plt.plot(h.history['acc'], label='train accuracy')\n",
        "plt.plot(h.history['val_acc'], label='validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vXL8wRSLIGB"
      },
      "source": [
        "**Predictive System**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkNgEehBK-6n"
      },
      "outputs": [],
      "source": [
        "input_image_path = input('Path of the image to be predicted: ')\n",
        "\n",
        "input_image = cv2.imread(input_image_path)\n",
        "\n",
        "cv2_imshow(input_image)\n",
        "\n",
        "input_image_resized = cv2.resize(input_image, (128,128))\n",
        "\n",
        "input_image_scaled = input_image_resized/255\n",
        "\n",
        "input_image_reshaped = np.reshape(input_image_scaled, [1,128,128,3])\n",
        "\n",
        "input_prediction = model.predict(input_image_reshaped)\n",
        "\n",
        "print(input_prediction)\n",
        "\n",
        "\n",
        "input_pred_label = np.argmax(input_prediction)\n",
        "\n",
        "print(input_pred_label)\n",
        "\n",
        "\n",
        "if input_pred_label == 1:\n",
        "\n",
        "  print('The person in the image is wearing a mask')\n",
        "\n",
        "else:\n",
        "\n",
        "  print('The person in the image is not wearing a mask')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAJstQknLQaU"
      },
      "outputs": [],
      "source": [
        "input_image_path = input('Path of the image to be predicted: ')\n",
        "\n",
        "input_image = cv2.imread(input_image_path)\n",
        "\n",
        "cv2_imshow(input_image)\n",
        "\n",
        "input_image_resized = cv2.resize(input_image, (128,128))\n",
        "\n",
        "input_image_scaled = input_image_resized/255\n",
        "\n",
        "input_image_reshaped = np.reshape(input_image_scaled, [1,128,128,3])\n",
        "\n",
        "input_prediction = model.predict(input_image_reshaped)\n",
        "\n",
        "print(input_prediction)\n",
        "\n",
        "\n",
        "input_pred_label = np.argmax(input_prediction)\n",
        "\n",
        "print(input_pred_label)\n",
        "\n",
        "\n",
        "if input_pred_label == 1:\n",
        "\n",
        "  print('The person in the image is wearing a mask')\n",
        "\n",
        "else:\n",
        "\n",
        "  print('The person in the image is not wearing a mask')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "cell_execution_strategy": "setup",
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
